{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include DomainML src in module path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bypass issues with invoking notebook with server arguments\n",
    "sys.argv.clear()\n",
    "sys.argv.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from src.features import preprocessing\n",
    "\n",
    "class MinimalMimicPreprocessorConfig:\n",
    "    admission_file: Path = Path(\"data/ADMISSIONS.csv\")\n",
    "    diagnosis_file: Path = Path(\"data/DIAGNOSES_ICD.csv\")\n",
    "    min_admissions_per_user: int = 2\n",
    "    add_icd9_info_to_sequences: bool = False # Avoid this if possible, because web requests are slow\n",
    "    cluster_file: Path = Path(\"data/invalid.file\") # This file must not exist\n",
    "    replace_keys: List[str] = []\n",
    "    prediction_column: str = \"\"\n",
    "\n",
    "sequences_df = preprocessing.MimicPreprocessor(MinimalMimicPreprocessorConfig()).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import sequences\n",
    "\n",
    "sequence_column_name = \"icd9_code_converted_3digits\"\n",
    "\n",
    "transformer = sequences.load_sequence_transformer()\n",
    "metadata = transformer.collect_metadata(sequences_df, sequence_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "sequence_df_pkl_file = \"data/sequences_df.pkl\"\n",
    "dataset_shuffle_buffer = 1000\n",
    "dataset_shuffle_seed = 12345\n",
    "batch_size = 32\n",
    "\n",
    "tensorflow_seed = 7796\n",
    "random_seed = 82379498237\n",
    "\n",
    "tf.random.set_seed(tensorflow_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "sequences_df.to_pickle(sequence_df_pkl_file)\n",
    "\n",
    "train_dataset = (tf.data.Dataset.from_generator(sequences.generate_train,\n",
    "args=(sequence_df_pkl_file, sequence_column_name), output_types=(tf.float32, tf.float32))\n",
    ".cache(\"\")\n",
    ".shuffle(dataset_shuffle_buffer, dataset_shuffle_seed, reshuffle_each_iteration=True)\n",
    ".batch(batch_size)\n",
    ".prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "test_dataset = (tf.data.Dataset.from_generator(sequences.generate_test,\n",
    "args=(sequence_df_pkl_file, sequence_column_name),\n",
    "output_types=(tf.float32, tf.float32))\n",
    ".cache(\"\")\n",
    ".batch(batch_size)\n",
    ".prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features import knowledge\n",
    "\n",
    "class MinimalICD9HierarchyPreprocessorConfig:\n",
    "    replace_keys: List[str] = []\n",
    "    prediction_column: str = \"\"\n",
    "    icd9_file: Path = Path(\"data/icd9.csv\")\n",
    "\n",
    "hierarchy_df = preprocessing.ICD9HierarchyPreprocessor(MinimalICD9HierarchyPreprocessorConfig()).load_data()\n",
    "hierarchy = knowledge.HierarchyKnowledge(knowledge.KnowledgeConfig())\n",
    "hierarchy.build_hierarchy_from_df(hierarchy_df, metadata.x_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import models\n",
    "\n",
    "model = models.GramModel()\n",
    "model.build(metadata, hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_classification = False\n",
    "n_epochs = 10\n",
    "\n",
    "model.train_dataset(train_dataset, test_dataset, multilabel_classification, n_epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36913b3a8fdee247ab31c445bb99cd1b610e5fce5968ec944dddf0bd9ac2faba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('healthcare-aiops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
